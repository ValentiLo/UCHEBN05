# **ПМ05. Отладка приложения интернет-магазина**

## **1. Стратегия отладки и инструменты**

### **1.1. Технологический стек для отладки**

```yaml
# Инструменты отладки
backend_debugging: 
  - "Django Debug Toolbar"
  - "pdb/ipdb/pudb"
  - "django-extensions"
  - "sentry"
  - "loguru"

frontend_debugging:
  - "React Developer Tools"
  - "Redux DevTools"
  - "Chrome DevTools"
  - "React Error Boundary"

database_debugging:
  - "pgAdmin/PostgreSQL logs"
  - "Django ORM query logging"
  - "EXPLAIN ANALYZE"

performance_debugging:
  - "Django Silk"
  - "Chrome Performance Tab"
  - "Lighthouse"
  - "New Relic"
```

---

## **2. Настройка окружения для отладки**

### **2.1. Конфигурация Django для разработки**

```python
# settings/dev.py
import os
from .base import *

DEBUG = True

# Django Debug Toolbar
INSTALLED_APPS += [
    'debug_toolbar',
    'django_extensions',
    'silk',
]

MIDDLEWARE = [
    'silk.middleware.SilkyMiddleware',
    'debug_toolbar.middleware.DebugToolbarMiddleware',
] + MIDDLEWARE

# Настройки Debug Toolbar
INTERNAL_IPS = [
    '127.0.0.1',
    'localhost',
]

DEBUG_TOOLBAR_PANELS = [
    'debug_toolbar.panels.history.HistoryPanel',
    'debug_toolbar.panels.versions.VersionsPanel',
    'debug_toolbar.panels.timer.TimerPanel',
    'debug_toolbar.panels.settings.SettingsPanel',
    'debug_toolbar.panels.headers.HeadersPanel',
    'debug_toolbar.panels.request.RequestPanel',
    'debug_toolbar.panels.sql.SQLPanel',
    'debug_toolbar.panels.staticfiles.StaticFilesPanel',
    'debug_toolbar.panels.templates.TemplatesPanel',
    'debug_toolbar.panels.cache.CachePanel',
    'debug_toolbar.panels.signals.SignalsPanel',
    'debug_toolbar.panels.logging.LoggingPanel',
    'debug_toolbar.panels.redirects.RedirectsPanel',
]

# Логирование SQL запросов
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'handlers': {
        'console': {
            'level': 'DEBUG',
            'class': 'logging.StreamHandler',
        },
        'file': {
            'level': 'DEBUG',
            'class': 'logging.FileHandler',
            'filename': 'debug.log',
        },
    },
    'loggers': {
        'django.db.backends': {
            'level': 'DEBUG',
            'handlers': ['console'],
        },
        'ecommerce': {
            'level': 'DEBUG',
            'handlers': ['console', 'file'],
            'propagate': False,
        },
    },
}

# Silk для профилирования
SILKY_PYTHON_PROFILER = True
SILKY_META = True
```

### **2.2. Настройка логирования**

```python
# core/logging_config.py
import logging
from loguru import logger
import sys

def setup_logging():
    """Настройка комплексного логирования"""
    
    # Intercept standard logging
    class InterceptHandler(logging.Handler):
        def emit(self, record):
            # Get corresponding Loguru level if it exists
            try:
                level = logger.level(record.levelname).name
            except ValueError:
                level = record.levelno
            
            # Find caller from where originated the logged message
            frame, depth = logging.currentframe(), 2
            while frame.f_code.co_filename == logging.__file__:
                frame = frame.f_back
                depth += 1
            
            logger.opt(depth=depth, exception=record.exc_info).log(
                level, record.getMessage()
            )
    
    # Setup Loguru
    logger.remove()
    logger.add(
        "logs/debug_{time:YYYY-MM-DD}.log",
        level="DEBUG",
        rotation="10 MB",
        retention="30 days",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {module}:{function}:{line} | {message}"
    )
    logger.add(
        sys.stderr,
        level="INFO",
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{module}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | <level>{message}</level>"
    )
    
    # Intercept standard logging
    logging.basicConfig(handlers=[InterceptHandler()], level=0)

# Инициализация логирования
setup_logging()
```

---

## **3. Инструменты отладки backend**

### **3.1. Кастомные middleware для отладки**

```python
# core/middleware/debug_middleware.py
import time
import logging
from django.db import connection
from django.utils.deprecation import MiddlewareMixin

logger = logging.getLogger(__name__)

class QueryDebugMiddleware(MiddlewareMixin):
    """Middleware для логирования SQL запросов"""
    
    def process_request(self, request):
        request.start_time = time.time()
        request.queries_before = len(connection.queries)
    
    def process_response(self, request, response):
        if hasattr(request, 'start_time'):
            duration = time.time() - request.start_time
            queries_after = len(connection.queries)
            queries_count = queries_after - getattr(request, 'queries_before', 0)
            
            if queries_count > 10:  # Логируем только проблемные запросы
                logger.warning(
                    f"High query count: {queries_count} queries in {duration:.2f}s "
                    f"for {request.path}"
                )
            
            if duration > 2.0:  # Логируем медленные запросы
                logger.error(
                    f"Slow request: {duration:.2f}s for {request.path} "
                    f"({queries_count} queries)"
                )
        
        return response

class RequestLogMiddleware(MiddlewareMixin):
    """Middleware для логирования запросов"""
    
    def process_request(self, request):
        logger.info(f"Request: {request.method} {request.path}")
    
    def process_response(self, request, response):
        logger.info(f"Response: {response.status_code} for {request.method} {request.path}")
        return response
```

### **3.2. Декораторы для отладки**

```python
# core/decorators.py
import time
import functools
from django.db import connection
from loguru import logger

def debug_queries(func):
    """Декоратор для отладки SQL запросов"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        initial_queries = len(connection.queries)
        start_time = time.time()
        
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            final_queries = len(connection.queries)
            query_count = final_queries - initial_queries
            duration = time.time() - start_time
            
            logger.debug(
                f"Function {func.__name__}: {query_count} queries in {duration:.4f}s"
            )
            
            if query_count > 5:
                logger.warning(
                    f"High query count in {func.__name__}: {query_count} queries"
                )
    
    return wrapper

def time_execution(func):
    """Декоратор для измерения времени выполнения"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            duration = time.time() - start_time
            logger.debug(f"Function {func.__name__} executed in {duration:.4f}s")
            
            if duration > 1.0:
                logger.warning(f"Slow function {func.__name__}: {duration:.4f}s")
    
    return wrapper

def log_exceptions(func):
    """Декоратор для логирования исключений"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(
                f"Exception in {func.__name__}: {str(e)}",
                exc_info=True
            )
            raise
    
    return wrapper
```

---

## **4. Отладка производительности**

### **4.1. Профилирование SQL запросов**

```python
# modules/products/services/debug_services.py
from django.db import connection
from loguru import logger

class QueryDebugService:
    
    @staticmethod
    def analyze_slow_queries():
        """Анализ медленных SQL запросов"""
        from django.db import connection
        
        slow_queries = []
        for query in connection.queries:
            if float(query['time']) > 0.1:  # Запросы дольше 100ms
                slow_queries.append({
                    'sql': query['sql'],
                    'time': query['time'],
                    'explain': QueryDebugService._explain_query(query['sql'])
                })
        
        return slow_queries
    
    @staticmethod
    def _explain_query(sql):
        """EXPLAIN ANALYZE для SQL запроса"""
        try:
            with connection.cursor() as cursor:
                cursor.execute(f"EXPLAIN ANALYZE {sql}")
                return cursor.fetchall()
        except Exception as e:
            return f"Explain failed: {str(e)}"
    
    @staticmethod
    def find_n_plus_one_queries():
        """Поиск N+1 проблем в запросах"""
        from modules.products.models import Product, Category
        
        # Пример обнаружения N+1
        products = Product.objects.all()[:10]
        
        problem_queries = []
        for product in products:
            # Этот вызов может вызвать N+1 проблему
            category_name = product.category.name  # Дополнительный запрос для каждого продукта
            
            if len(connection.queries) > 15:  # Если слишком много запросов
                problem_queries.append({
                    'product_id': product.id,
                    'queries_count': len(connection.queries)
                })
        
        return problem_queries

# Использование в views
@debug_queries
@time_execution
def product_list_debug(request):
    """Отладочная view для анализа производительности"""
    products = Product.objects.select_related('category').prefetch_related('images')[:20]
    
    # Анализ запросов
    slow_queries = QueryDebugService.analyze_slow_queries()
    n_plus_one = QueryDebugService.find_n_plus_one_queries()
    
    return JsonResponse({
        'slow_queries': slow_queries,
        'n_plus_one_problems': n_plus_one,
        'total_queries': len(connection.queries)
    })
```

### **4.2. Профилирование памяти**

```python
# core/profiling/memory_profiler.py
import tracemalloc
import linecache
from loguru import logger

class MemoryProfiler:
    
    def __init__(self):
        tracemalloc.start()
    
    def snapshot_memory(self, label=""):
        """Создание снимка использования памяти"""
        snapshot = tracemalloc.take_snapshot()
        
        logger.info(f"Memory snapshot {label}:")
        for stat in snapshot.statistics('lineno')[:10]:
            logger.info(f"  {stat}")
        
        return snapshot
    
    def compare_snapshots(self, snapshot1, snapshot2):
        """Сравнение двух снимков памяти"""
        differences = snapshot2.compare_to(snapshot1, 'lineno')
        
        logger.info("Memory differences:")
        for stat in differences[:10]:
            logger.info(f"  {stat}")
        
        return differences
    
    def find_memory_leaks(self):
        """Поиск утечек памяти"""
        snapshot = tracemalloc.take_snapshot()
        
        logger.info("Top memory usage:")
        for stat in snapshot.statistics('lineno')[:5]:
            logger.info(f"  {stat}")
            
            # Показываем соответствующий код
            frame = stat.traceback[0]
            filename = frame.filename
            lineno = frame.lineno
            
            line = linecache.getline(filename, lineno).strip()
            if line:
                logger.info(f"    Code: {line}")

# Использование
profiler = MemoryProfiler()

@time_execution
def memory_intensive_operation():
    snapshot1 = profiler.snapshot_memory("Before operation")
    
    # Операция, которая может использовать много памяти
    large_list = [i for i in range(1000000)]
    
    snapshot2 = profiler.snapshot_memory("After operation")
    profiler.compare_snapshots(snapshot1, snapshot2)
```

---

## **5. Отладка фронтенда**

### **5.1. React Error Boundary**

```tsx
// components/Debug/ErrorBoundary.tsx
import React from 'react';
import { logError } from '../../services/loggingService';

interface ErrorBoundaryState {
  hasError: boolean;
  error?: Error;
  errorInfo?: React.ErrorInfo;
}

export class ErrorBoundary extends React.Component<
  { children: React.ReactNode; fallback?: React.ReactNode },
  ErrorBoundaryState
> {
  constructor(props: any) {
    super(props);
    this.state = { hasError: false };
  }

  static getDerivedStateFromError(error: Error): ErrorBoundaryState {
    return { hasError: true, error };
  }

  componentDidCatch(error: Error, errorInfo: React.ErrorInfo) {
    this.setState({
      error,
      errorInfo
    });

    // Логирование ошибки
    logError('React Error Boundary', {
      error: error.message,
      stack: error.stack,
      componentStack: errorInfo.componentStack
    });

    // Отправка в Sentry (если подключен)
    if ((window as any).Sentry) {
      (window as any).Sentry.captureException(error, { extra: errorInfo });
    }
  }

  render() {
    if (this.state.hasError) {
      if (this.props.fallback) {
        return this.props.fallback;
      }

      return (
        <div className="error-boundary">
          <h2>Something went wrong</h2>
          <details style={{ whiteSpace: 'pre-wrap' }}>
            {this.state.error && this.state.error.toString()}
            <br />
            {this.state.errorInfo?.componentStack}
          </details>
          <button 
            onClick={() => this.setState({ hasError: false })}
            className="retry-button"
          >
            Try Again
          </button>
        </div>
      );
    }

    return this.props.children;
  }
}

// Компонент для отладки производительности
export const PerformanceDebugger: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  const startTime = React.useRef(performance.now());
  const [renderTime, setRenderTime] = React.useState(0);

  React.useEffect(() => {
    const endTime = performance.now();
    const duration = endTime - startTime.current;
    setRenderTime(duration);

    if (duration > 100) { // Если рендер дольше 100ms
      console.warn(`Slow render detected: ${duration}ms`);
    }
  });

  return (
    <div className="performance-debugger">
      <div className="debug-info">
        Render time: {renderTime.toFixed(2)}ms
      </div>
      {children}
    </div>
  );
};
```

### **5.2. Redux Debug Middleware**

```typescript
// store/debugMiddleware.ts
import { Middleware } from '@reduxjs/toolkit';

export const debugMiddleware: Middleware = (store) => (next) => (action) => {
  const startTime = performance.now();
  
  console.group(`Redux Action: ${action.type}`);
  console.log('Payload:', action.payload);
  console.log('State before:', store.getState());
  
  const result = next(action);
  
  console.log('State after:', store.getState());
  console.log(`Action processed in: ${(performance.now() - startTime).toFixed(2)}ms`);
  console.groupEnd();
  
  return result;
};

export const crashReporter: Middleware = (store) => (next) => (action) => {
  try {
    return next(action);
  } catch (err) {
    console.error('Redux Error:', err);
    console.error('Action that caused error:', action);
    console.error('Current state:', store.getState());
    
    // Отправка ошибки на сервер
    fetch('/api/log-error', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        type: 'redux_error',
        error: err.toString(),
        action,
        state: store.getState()
      })
    });
    
    throw err;
  }
};
```

### **5.3. Хуки для отладки**

```typescript
// hooks/useDebug.ts
import { useEffect, useRef } from 'react';

export const useWhyDidYouUpdate = (name: string, props: any) => {
  const previousProps = useRef<any>();

  useEffect(() => {
    if (previousProps.current) {
      const allKeys = Object.keys({ ...previousProps.current, ...props });
      const changes: any = {};

      allKeys.forEach(key => {
        if (previousProps.current[key] !== props[key]) {
          changes[key] = {
            from: previousProps.current[key],
            to: props[key]
          };
        }
      });

      if (Object.keys(changes).length > 0) {
        console.log('[why-did-you-update]', name, changes);
      }
    }

    previousProps.current = props;
  });
};

export const useRenderCount = (componentName: string) => {
  const renderCount = useRef(0);
  
  renderCount.current += 1;
  
  useEffect(() => {
    console.log(`[render-count] ${componentName} rendered ${renderCount.current} times`);
    
    if (renderCount.current > 10) {
      console.warn(`[render-count] ${componentName} is rendering too frequently!`);
    }
  });
  
  return renderCount.current;
};
```

---

## **6. Интеграция с Sentry для мониторинга ошибок**

### **6.1. Настройка Sentry**

```python
# core/sentry_config.py
import sentry_sdk
from sentry_sdk.integrations.django import DjangoIntegration
from sentry_sdk.integrations.redis import RedisIntegration
from sentry_sdk.integrations.celery import CeleryIntegration

def init_sentry():
    """Инициализация Sentry для мониторинга ошибок"""
    sentry_sdk.init(
        dsn=os.getenv('SENTRY_DSN'),
        integrations=[
            DjangoIntegration(),
            RedisIntegration(),
            CeleryIntegration(),
        ],
        # Настройки трассировки
        traces_sample_rate=0.1,  # 10% трассировок для производительности
        profiles_sample_rate=0.1, # 10% профилирований
        
        # Отладочная информация
        send_default_pii=True,  # Персональные данные для отладки
        environment=os.getenv('ENVIRONMENT', 'development'),
        
        # Фильтрация ошибок
        before_send=before_send_filter,
        before_breadcrumb=before_breadcrumb_filter,
    )

def before_send_filter(event, hint):
    """Фильтр для отправки событий в Sentry"""
    # Игнорировать определенные типы ошибок
    if 'exc_info' in hint:
        exc_type, exc_value, tb = hint['exc_info']
        if isinstance(exc_value, SomeSpecificError):
            return None  # Не отправлять эту ошибку
    
    # Добавить дополнительную информацию
    event.setdefault('tags', {}).update({
        'debug_mode': str(DEBUG),
    })
    
    return event

def before_breadcrumb_filter(crumb, hint):
    """Фильтр для хлебных крошек"""
    # Игнорировать определенные крошки
    if crumb.get('category') == 'console':
        return None
    
    return crumb
```

---

## **7. Автоматизированное тестирование для отладки**

### **7.1. Тесты для поиска проблем**

```python
# tests/debug_tests.py
import pytest
from django.test import TestCase
from django.db import connection
from core.decorators import debug_queries

class DebugTests(TestCase):
    
    def test_n_plus_one_queries(self):
        """Тест для обнаружения N+1 проблем"""
        from modules.products.models import Product, Category
        
        # Создание тестовых данных
        category = Category.objects.create(name="Test Category")
        for i in range(5):
            Product.objects.create(
                name=f"Product {i}",
                price=100,
                category=category
            )
        
        # Тестирование на N+1
        with self.assertNumQueries(2):  # Ожидаем только 2 запроса
            products = Product.objects.select_related('category').all()
            for product in products:
                category_name = product.category.name  # Не должно вызывать дополнительные запросы
    
    def test_slow_query_detection(self):
        """Тест для обнаружения медленных запросов"""
        from modules.products.services.search_service import ProductSearchService
        
        start_time = time.time()
        
        # Выполнение потенциально медленной операции
        results = ProductSearchService.search_products(
            query="test",
            sort_by="relevance"
        )
        
        duration = time.time() - start_time
        self.assertLess(duration, 1.0, "Query took too long")
    
    def test_memory_usage(self):
        """Тест использования памяти"""
        import tracemalloc
        
        tracemalloc.start()
        
        snapshot1 = tracemalloc.take_snapshot()
        
        # Операция, которая может использовать много памяти
        large_list = [i for i in range(100000)]
        
        snapshot2 = tracemalloc.take_snapshot()
        
        # Проверка, что память не утекает
        memory_diff = snapshot2.compare_to(snapshot1, 'lineno')
        total_memory_increase = sum(stat.size for stat in memory_diff)
        
        self.assertLess(total_memory_increase, 1024 * 1024, "Memory leak detected")  # 1MB

@pytest.mark.debug
def test_concurrent_requests():
    """Тест конкурентных запросов для поиска race conditions"""
    import threading
    from django.test import Client
    
    client = Client()
    results = []
    errors = []
    
    def make_request():
        try:
            response = client.get('/api/products/')
            results.append(response.status_code)
        except Exception as e:
            errors.append(str(e))
    
    # Создание нескольких потоков
    threads = []
    for i in range(10):
        thread = threading.Thread(target=make_request)
        threads.append(thread)
        thread.start()
    
    # Ожидание завершения
    for thread in threads:
        thread.join()
    
    assert not errors, f"Concurrent requests failed: {errors}"
    assert all(code == 200 for code in results), "Not all requests succeeded"
```

---

## **8. Скрипты для автоматической отладки**

### **8.1. Скрипт диагностики системы**

```python
# scripts/system_diagnostic.py
#!/usr/bin/env python
import os
import sys
import django
import logging
from datetime import datetime

# Настройка Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings.dev')
django.setup()

from django.db import connection
from django.core.cache import cache
from loguru import logger

class SystemDiagnostic:
    """Класс для диагностики системы"""
    
    def run_full_diagnostic(self):
        """Запуск полной диагностики системы"""
        logger.info("Starting system diagnostic...")
        
        checks = [
            self.check_database_connection,
            self.check_cache_connection,
            self.check_migrations,
            self.check_static_files,
            self.check_celery_workers,
            self.check_redis_connection,
            self.check_disk_space,
            self.check_memory_usage,
        ]
        
        results = {}
        for check in checks:
            try:
                result = check()
                results[check.__name__] = result
                logger.info(f"✓ {check.__name__}: {result['status']}")
            except Exception as e:
                results[check.__name__] = {'status': 'ERROR', 'error': str(e)}
                logger.error(f"✗ {check.__name__}: {str(e)}")
        
        self.generate_report(results)
        return results
    
    def check_database_connection(self):
        """Проверка подключения к базе данных"""
        try:
            with connection.cursor() as cursor:
                cursor.execute("SELECT 1")
                result = cursor.fetchone()
            
            return {
                'status': 'OK',
                'details': 'Database connection successful'
            }
        except Exception as e:
            return {
                'status': 'ERROR',
                'error': str(e)
            }
    
    def check_cache_connection(self):
        """Проверка подключения к кэшу"""
        try:
            cache.set('diagnostic_test', 'test_value', 10)
            value = cache.get('diagnostic_test')
            
            if value == 'test_value':
                return {
                    'status': 'OK',
                    'details': 'Cache connection successful'
                }
            else:
                return {
                    'status': 'ERROR',
                    'error': 'Cache test failed'
                }
        except Exception as e:
            return {
                'status': 'ERROR',
                'error': str(e)
            }
    
    def check_migrations(self):
        """Проверка применения миграций"""
        from django.core.management import execute_from_command_line
        
        try:
            execute_from_command_line(['manage.py', 'migrate', '--check'])
            return {
                'status': 'OK',
                'details': 'All migrations applied'
            }
        except SystemExit:
            return {
                'status': 'WARNING',
                'details': 'Pending migrations found'
            }
    
    def generate_report(self, results):
        """Генерация отчета диагностики"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'results': results,
            'summary': {
                'total_checks': len(results),
                'passed_checks': sum(1 for r in results.values() if r['status'] == 'OK'),
                'failed_checks': sum(1 for r in results.values() if r['status'] == 'ERROR'),
                'warnings': sum(1 for r in results.values() if r['status'] == 'WARNING'),
            }
        }
        
        logger.info("Diagnostic report:")
        logger.info(f"Total checks: {report['summary']['total_checks']}")
        logger.info(f"Passed: {report['summary']['passed_checks']}")
        logger.info(f"Failed: {report['summary']['failed_checks']}")
        logger.info(f"Warnings: {report['summary']['warnings']}")
        
        # Сохранение отчета в файл
        with open('diagnostic_report.json', 'w') as f:
            import json
            json.dump(report, f, indent=2)
        
        return report

if __name__ == '__main__':
    diagnostic = SystemDiagnostic()
    diagnostic.run_full_diagnostic()
```

### **8.2. Скрипт мониторинга в реальном времени**

```python
# scripts/live_monitor.py
#!/usr/bin/env python
import time
import psutil
import requests
from datetime import datetime
from loguru import logger

class LiveMonitor:
    """Мониторинг системы в реальном времени"""
    
    def __init__(self, check_interval=5):
        self.check_interval = check_interval
        self.thresholds = {
            'cpu_percent': 80,
            'memory_percent': 85,
            'disk_percent': 90,
            'response_time': 2.0,
        }
    
    def start_monitoring(self):
        """Запуск мониторинга"""
        logger.info("Starting live monitoring...")
        
        try:
            while True:
                self.check_system_health()
                self.check_application_health()
                time.sleep(self.check_interval)
        except KeyboardInterrupt:
            logger.info("Monitoring stopped")
    
    def check_system_health(self):
        """Проверка здоровья системы"""
        # CPU
        cpu_percent = psutil.cpu_percent(interval=1)
        if cpu_percent > self.thresholds['cpu_percent']:
            logger.warning(f"High CPU usage: {cpu_percent}%")
        
        # Memory
        memory = psutil.virtual_memory()
        if memory.percent > self.thresholds['memory_percent']:
            logger.warning(f"High memory usage: {memory.percent}%")
        
        # Disk
        disk = psutil.disk_usage('/')
        if disk.percent > self.thresholds['disk_percent']:
            logger.warning(f"High disk usage: {disk.percent}%")
    
    def check_application_health(self):
        """Проверка здоровья приложения"""
        try:
            start_time = time.time()
            response = requests.get('http://localhost:8000/health/', timeout=5)
            response_time = time.time() - start_time
            
            if response.status_code != 200:
                logger.error(f"Application health check failed: {response.status_code}")
            
            if response_time > self.thresholds['response_time']:
                logger.warning(f"Slow response time: {response_time:.2f}s")
            
            logger.info(f"App health: {response.status_code} in {response_time:.2f}s")
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Application health check error: {str(e)}")

if __name__ == '__main__':
    monitor = LiveMonitor()
    monitor.start_monitoring()
```

---

## **9. Чек-лист отладки**

### **9.1. Чек-лист для распространенных проблем**

```markdown
# Чек-лист отладки интернет-магазина

## 🐛 Общие проблемы
- [ ] Проверить логи ошибок
- [ ] Воспроизвести проблему в dev среде
- [ ] Проверить последние изменения в коде

## 🗄️ Проблемы с базой данных
- [ ] Проверить подключение к БД
- [ ] Проверить миграции
- [ ] Проанализировать медленные запросы
- [ ] Проверить N+1 проблемы

## 🎨 Проблемы с фронтендом
- [ ] Проверить консоль браузера на ошибки
- [ ] Проверить Network tab в DevTools
- [ ] Проверить состояние Redux store
- [ ] Проверить React компоненты на re-renders

## ⚡ Проблемы с производительностью
- [ ] Проверить время ответа сервера
- [ ] Проанализировать использование памяти
- [ ] Проверить кэширование
- [ ] Оптимизировать изображения

## 🔐 Проблемы с безопасностью
- [ ] Проверить CORS настройки
- [ ] Проверить CSRF токены
- [ ] Проверить валидацию данных
- [ ] Проверить авторизацию

## 🛠️ Инструменты для быстрой отладки
1. Django Debug Toolbar - для анализа запросов
2. React DevTools - для отладки компонентов
3. Redux DevTools - для отладки состояния
4. Chrome DevTools - для профилирования
5. Sentry - для мониторинга ошибок
```

Данная система отладки обеспечивает:

1. **Комплексный мониторинг** ошибок в реальном времени
2. **Детальный анализ** производительности на всех уровнях
3. **Автоматизированную диагностику** распространенных проблем
4. **Эффективные инструменты** для быстрого поиска и исправления багов
5. **Проактивное обнаружение** проблем до их появления в продакшене
